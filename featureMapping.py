'''This module contains the featureMapping network, which takes in the feature vectors generated by 
the encode half of the componentEmbedding network and outputs and image size representation with 
32 features per pixel'''
import torch
from torch import nn
from torch.utils.checkpoint import checkpoint

from buildingBlocks import ConvBlock, ResnetBlock, ConvTransBlock, FullyConnected, makeOptimizer

torch.set_default_tensor_type(torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor)

class FeatureDecoder(nn.Module):
    def __init__(self, size):
        super(FeatureDecoder, self).__init__()

        self.fullyConnected = FullyConnected(inputSize=512, outputSize=(512, int(size/32), int(size/32)))

        self.resBlock1 = ResnetBlock(int(size/32))
        self.conv1 = ConvTransBlock(inputSize=(512, int(size/32), int(size/32)), outputSize=(256, int(size/16), int(size/16)))

        self.resBlock2 = ResnetBlock(int(size/16))
        self.conv2 = ConvTransBlock(inputSize=(256, int(size/16), int(size/16)), outputSize=(256, int(size/8), int(size/8)))

        self.resBlock3 = ResnetBlock(int(size/8))
        self.conv3 = ConvTransBlock(inputSize=(256, int(size/8), int(size/8)), outputSize=(128, int(size/4), int(size/4)))

        self.resBlock4 = ResnetBlock(int(size/4))
        self.conv4 = ConvTransBlock(inputSize=(128, int(size/4), int(size/4)), outputSize=(64, int(size/2), int(size/2)))
        
        self.resBlock5 = ResnetBlock(int(size/2))
        self.conv5 = ConvTransBlock(inputSize=(64, int(size/2), int(size/2)), outputSize=(64, size, size))

        self.resBlock6 = ResnetBlock(size)
        self.conv6 = ConvBlock(inputSize=(64, size, size), outputSize=(32, size,size))

    def forward(self, x):
        x = self.fullyConnected(x)
        x = self.conv1(self.resBlock1(x))
        x = self.conv2(self.resBlock2(x))
        x = self.conv3(self.resBlock3(x))
        x = self.conv4(self.resBlock4(x))
        x = self.conv5(self.resBlock5(x))
        x = self.conv6(self.resBlock6(x))
        return x


class FeatureMapping:
    def __init__(self):
        super(FeatureMapping, self).__init__()

        #Decoders for each facial feature:
        self.decoders = [
            FeatureDecoder(64),  # left eye
            FeatureDecoder(64),  # right eye
            FeatureDecoder(84),  # nose
            FeatureDecoder(96),  # mouth
            FeatureDecoder(256)  # rest of face
        ]

        self.optimizers = [makeOptimizer(decoder) for decoder in self.decoders]

    def __call__(self, featureVectors):
        leftEye, rightEye, nose, mouth, face = [decoder(feature) for decoder, feature in zip(self.decoders, featureVectors)]
        face[:, :, 143:239, 80:176] = mouth
        face[:, :, 103:187, 86:170] = nose
        face[:, :, 90:154, 64:128] = rightEye
        face[:, :, 90:154, 126:190] = leftEye

        return face

    def step(self):
        for optim in self.optimizers:
            optim.step()

    def zero_grad(self):
        for optim in self.optimizers:
            optim.zero_grad()

    def weightUpdate(self):
        self.step()
        self.zero_grad()

    def eval(self):
        for decoder in self.decoders:
            decoder.eval()